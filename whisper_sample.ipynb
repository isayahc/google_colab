{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMms805Gej1oQKa0CdFSCEl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isayahc/google_colab/blob/main/whisper_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube\n",
        "!pip install -U openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuiIyU3r_dgk",
        "outputId": "b9041b7c-a0ff-41f6-edee-e345773fdcab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20230314)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (9.1.0)\n",
            "Requirement already satisfied: tiktoken==0.3.1 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.3.1)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2.27.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.12.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (16.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "import whisper\n",
        "import os"
      ],
      "metadata": {
        "id": "_dtD5mzm_jMJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the YouTube video URL\n",
        "video_url = \"https://youtu.be/aygSMgK3BEM\"\n",
        "\n",
        "# Specify the output path for the downloaded video\n",
        "output_path = \"/content\"\n",
        "\n",
        "# Download the YouTube video\n",
        "youtube = YouTube(video_url)\n",
        "video = youtube.streams.get_highest_resolution()\n",
        "video.download(output_path=output_path, filename=\"audio.wav\")\n",
        "\n",
        "# Rename the downloaded video to \"audio.mp3\"\n",
        "# os.rename(os.path.join(output_path, \"audio.mp4\"), os.path.join(output_path, \"audio.mp3\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4ZrgHx9p_kDs",
        "outputId": "a4dcc8c6-8a78-4c5f-a0f1-83d92ea368b2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/audio.wav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"large-v2\")\n",
        "result = model.transcribe(\"audio.wav\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhfwUJhx_nPY",
        "outputId": "ac9f113a-56b0-4c02-f6b9-16e0fd31cd16"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The Thinking Machine Hello again. With me tonight is Professor Jerome B. Wiesner, Director of the Research Laboratory of Electronics at MIT. Dr. Wiesner, what really worries me today is what's going to happen to us if machines can think. And what interests me specifically is, can they? Well, that's a very hard question to answer. If you'd asked me that question just a few years ago, I'd have said it was very far-fetched. Today I just have to admit I don't really know. I suspect if you come back in four or five years, I'll say, sure, they really do think. Well, if you're confused, Doctor, how do you think I feel? We're just really beginning to understand the capabilities of the computers. I've got some film to illustrate this point, which I think will amaze you. That man isn't playing checkers against the computer, is he? Sure, and it plays pretty well. While most computer scientists saw it as a mere number cruncher, a small group thought that the digital computer had a much grander destiny. Being a general-purpose machine, it could be programmed to do things which in humans require intelligence, play games like checkers and chess, and solve brain teasers. Let's see what it's printing out. The field became known as artificial intelligence. Can machines really think? Even the scientists argue that one. I'm convinced that machines can and will think. I don't mean that machines will behave like men. I don't think for a very long time we're going to have a difficult problem distinguishing a man from a robot. And I don't think my daughter will ever marry a computer. But I think the computers will be doing the things that men do when we say they're thinking. I'm convinced that machines can and will think in our lifetime. I confidently expect that within a matter of 10 or 15 years, something will emerge from the laboratories, which is not too far from the robot of science fiction fame. They hadn't reckoned with ambiguity when they set out to use computers to translate languages. A $500,000 super calculator, most versatile electronic brain known, translates Russian into English. Instead of mathematical wizardry, a sentence in Russian is to be fed into... One of the first non-numerical applications of computers, it was hyped as the solution to the Cold War obsession of keeping tabs on what the Russians were doing. Claims were made that the computer would replace most human translators. At present, of course, you're just in the experimental stage. When you go in for full-scale production, what will the capacity be? We should be able to do about, with a modern commercial computer, about one to two million words an hour. And this will be quite an adequate speed to cope with the whole output of the Soviet Union in just a few hours computer time a week. When do you hope to be able to achieve this speed? If our experiments go well, then perhaps within five years or so. And finally, Mr. McDaniel, does this mean the end of human translators? I'd say yes for translators of scientific and technical material, but as regards poetry and novels, no, I don't think we'll ever replace the translators of that type of material. Mr. McDaniel, thank you very much.\n"
          ]
        }
      ]
    }
  ]
}